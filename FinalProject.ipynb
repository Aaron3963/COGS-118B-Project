{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"COGS 118B Final Project\"\n",
    "author: \"Xueyan Shi, Yacheng Xiao, Yimeng Wang, Lin Zhou\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "jupyder: python3\n",
    "toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Game Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This study aims to predict the discount prices of games on Steam, along with the rich metadata and user-generated tags associated with each game. The dataset comprises 71,700 entries, game titles, original and discounted prices, release dates, developer and publisher information, supported languages, popular user tags, game features, and minimum requirements. These entries are primarily textual and categorical, with numerical representations for prices. Our methodology involves preprocessing the data, including handling missing values and transforming user-generated tags into one-hot encoded vectors to quantify the categorical data effectively. We will explore the dataset through exploratory data analysis (EDA) to uncover underlying patterns and relationships. The study will then apply clustering techniques, specifically DBSCAN, Spectral Clustering, and Gaussian Mixture Models (GMM), to group games based on their tags and features. This clustering will serve as a foundation for predicting game discount prices. The performance of our price prediction model will be evaluated using the Mean Absolute Error (MAE), while the effectiveness of our clustering approach will be assessed using the Adjusted Rand Index (ARI), ensuring a comprehensive evaluation of both the accuracy of price predictions and the quality of game groupings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "The exponential growth of the computer gaming industry into a multi-billion dollar industry shows its widespread popularity and economic significance. However, the industry faces unique challenges, such as the difficulty in satisfying a multicultural player base. Research indicates that implementing discount strategies is a crucial business tactic for bringing up sales in the competitive market. <a name=\"dunote\"></a>[<sup>[1]</sup>](#dunote)Previous studies have focused on predicting the timing of discounts for games, leveraging historical data to predict when price reductions are likely to occur.<a name=\"linnote\"></a>[<sup>[2]</sup>](#linnote) Building on this foundation, our research aims to predict not just the timing but the specific discount rates of computer games on steam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "We are aiming to predict the discount price of games in Steam. Games in steam are all labeled with tags and features, which makes it perfect for clustering algorithms. Though tags are generated by users, we can still transform it into one-hot encoding for it to be quantifiable. Measuring should be easy as we can use accuracy for predict prices, or use distance for clustering performance. We will use fixed seed to ensure the algorithm is replicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "We will be using the [Steam Games Dataset](https://www.kaggle.com/datasets/nikatomashvili/steam-games-dataset) from Kaggle. It has 71000 game data points, with around 15 variables, including `Price`, `Review Rate`, `Release Date`, `Tag`,.etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Steam_Game_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what an observation consist of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Original Price', 'Discounted Price', 'Release Date', 'Link',\n",
       "       'Game Description', 'Recent Reviews Summary', 'All Reviews Summary',\n",
       "       'Recent Reviews Number', 'All Reviews Number', 'Developer', 'Publisher',\n",
       "       'Supported Languages', 'Popular Tags', 'Game Features',\n",
       "       'Minimum Requirements'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RPG', 'Choices Matter', 'Character Customization', 'Story Rich', 'Adventure', 'Online Co-Op', 'CRPG', 'Multiplayer', 'Fantasy', 'Turn-Based Combat', 'Dungeons & Dragons', 'Co-op Campaign', 'Strategy', 'Singleplayer', 'Romance', 'Class-Based', 'Dark Fantasy', 'Combat', 'Controller', 'Stealth']\n",
      "['Single-player', 'Online Co-op', 'LAN Co-op', 'Steam Achievements', 'Full controller support', 'Steam Cloud']\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0].iloc[13]) # Tag\n",
    "print(df.iloc[0].iloc[14]) # Game Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was obtained via web-crawling, which is very raw and contains garbled characters. We need a lot of pre-processing to clean and prune the dataset so it is usable. Also, some features are presented with list, so we need a `dict` and remap it into one-hot encoding for ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "To address the challenge of predicting discount prices for Steam games and effectively clustering them based on tags and features, we propose a multi-faceted solution leveraging DBSCAN, Spectral Clustering, and Gaussian Mixture Models(GMM).\n",
    "\n",
    "#### DBSCAN (Density-Based Spatial Clustering of Applications with Noise):\n",
    "DBSCAN is chosen for its ability to identify clusters of varying shapes and sizes without the need for specifying the number of clusters a priori. This characteristic is particularly advantageous given the diverse and potentially irregular groupings of games based on tags. DBSCAN works by grouping closely packed points and identifying points in low-density areas as outliers. This method is expected to effectively segregate games into meaningful clusters based on similarity in tags and features, which are pivotal for predicting discount prices.\n",
    "\n",
    "#### Spectral Clustering:\n",
    "Spectral Clustering is selected for its effectiveness in identifying complex structures within data. It works by using the eigenvalues of a similarity matrix to perform dimensionality reduction before clustering in lower dimensions. This approach is particularly suited for our dataset since it can capture the intricate relationships between games based on their tags and features, which might not be linearly separable.\n",
    "\n",
    "#### Gaussian Mixture Models (GMM):\n",
    "GMM is a probabilistic model that assumes all data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. It offers flexibility in the shape of clusters, making it suitable for our dataset where games may naturally group into clusters with varying sizes and elliptical shapes. GMM's soft-clustering approach, where each point is assigned a probability of belonging to each cluster, provides a nuanced understanding of game groupings.\n",
    "\n",
    "#### Implementation:\n",
    "The implementation will utilize the scikit-learn library in Python:<br>\n",
    "DBSCAN (sklearn.cluster.DBSCAN): DBSCAN(eps=n, min_samples=n), adjusting eps and min_samples based on the dataset's density.<br>\n",
    "Spectral Clustering (sklearn.cluster.SpectralClustering): SpectralClustering(n_clusters=n), determining n_clusters after EDA and preliminary clustering attempts.<br>\n",
    "Gaussian Mixture Models (sklearn.mixture.GaussianMixture): GaussianMixture(n_components=n, covariance_type='full'), with n_components decided based on model performance and BIC (Bayesian Information Criterion) scores.<br>\n",
    "\n",
    "#### Model Evaluation:\n",
    "Clustering performance will be evaluated using the Adjusted Rand Index (ARI), and the predictive model's accuracy for discount prices will be assessed using Mean Absolute Error (MAE).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "**Prediction Accuracy**: Mean Absolute Error (MAE)\n",
    "\n",
    "It measures the average magnitude of errors in a set of predictions, without considering their direction. It's calculated as the average of the absolute differences between predicted values and actual values, making it a straightforward and interpretable metric for assessing price prediction accuracy\n",
    "\n",
    "**Clustering Performance**: Adjusted Ranked Index (ARI)\n",
    "\n",
    "The Adjusted Rand Index (ARI) measures the similarity between two clusterings, considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings. The ARI is adjusted for the chance grouping of elements, making it a more reliable metric for the quality of the clustering.\n",
    "\n",
    "MAE will give us a direct measure of the accuracy of the price predictions, while ARI will assess the effectiveness of our clustering, ensuring that the foundation for our predictions—how games are grouped based on tags and features—is sound. This dual approach allows us to optimize both the clustering of games and the accuracy of the price predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "This project leverages publicly available datasets from platforms such as Kaggle, with the intent of adhering strictly to academic research protocols and respecting all relevant data usage agreements. We take measures to address potential inaccuracies within our dataset by cross-referencing information with alternative, independent sources. We mainly focuses on public data provided by Steam, hence, we acknowledge that the insights may not be universally applicable to other gaming platform.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
